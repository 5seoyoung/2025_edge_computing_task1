#!/usr/bin/env python3
"""
GPU ì„œë²„ í™˜ê²½ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
"""
import torch
import sys
from pathlib import Path

def check_gpu():
    """GPU ë° í™˜ê²½ í™•ì¸"""
    print("="*70)
    print("GPU Server Environment Check")
    print("="*70)
    
    # PyTorch ë²„ì „
    print(f"\nğŸ“¦ PyTorch Version: {torch.__version__}")
    
    # CUDA í™•ì¸
    print(f"\nğŸ” CUDA Available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"   CUDA Version: {torch.version.cuda}")
        print(f"   cuDNN Version: {torch.backends.cudnn.version()}")
        print(f"   GPU Count: {torch.cuda.device_count()}")
        
        for i in range(torch.cuda.device_count()):
            print(f"\n   GPU {i}:")
            print(f"      Name: {torch.cuda.get_device_name(i)}")
            props = torch.cuda.get_device_properties(i)
            print(f"      Memory: {props.total_memory / 1024**3:.2f} GB")
            print(f"      Compute Capability: {props.major}.{props.minor}")
    else:
        print("   âš ï¸  CUDA not available. Please check:")
        print("      - CUDA drivers installed")
        print("      - PyTorch built with CUDA support")
        print("      - GPU accessible")
    
    # Python ë²„ì „
    print(f"\nğŸ Python Version: {sys.version}")
    
    # ì˜ì¡´ì„± í™•ì¸
    print(f"\nğŸ“š Dependencies:")
    try:
        import torchvision
        print(f"   âœ… torchvision: {torchvision.__version__}")
    except ImportError:
        print(f"   âŒ torchvision: Not installed")
    
    try:
        import cv2
        print(f"   âœ… opencv-python: {cv2.__version__}")
    except ImportError:
        print(f"   âŒ opencv-python: Not installed")
    
    try:
        import pandas
        print(f"   âœ… pandas: {pandas.__version__}")
    except ImportError:
        print(f"   âŒ pandas: Not installed")
    
    try:
        import numpy
        print(f"   âœ… numpy: {numpy.__version__}")
    except ImportError:
        print(f"   âŒ numpy: Not installed")
    
    # Config í™•ì¸
    print(f"\nâš™ï¸  Configuration:")
    try:
        from config import Config
        print(f"   Data Root: {Config.DATA_ROOT}")
        print(f"   Video Dir exists: {Config.VIDEO_DIR.exists()}")
        print(f"   FileList exists: {Config.FILELIST_PATH.exists()}")
        print(f"   Batch Size: {Config.BATCH_SIZE}")
        print(f"   Num Workers: {Config.NUM_WORKERS}")
        print(f"   Device: {Config.DEVICE}")
    except Exception as e:
        print(f"   âš ï¸  Config check failed: {e}")
    
    # ê¶Œì¥ ì‚¬í•­
    print(f"\nğŸ’¡ Recommendations:")
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if gpu_memory < 8:
            print(f"   - GPU Memory: {gpu_memory:.2f} GB (Small)")
            print(f"     Recommended BATCH_SIZE: 8-16")
        elif gpu_memory < 16:
            print(f"   - GPU Memory: {gpu_memory:.2f} GB (Medium)")
            print(f"     Recommended BATCH_SIZE: 16-32")
        else:
            print(f"   - GPU Memory: {gpu_memory:.2f} GB (Large)")
            print(f"     Recommended BATCH_SIZE: 32-64")
    else:
        print(f"   - Using CPU mode")
        print(f"     Recommended BATCH_SIZE: 4-8")
    
    print("\n" + "="*70)
    
    # ì¢…ë£Œ ì½”ë“œ
    if torch.cuda.is_available():
        print("âœ… GPU environment ready!")
        return 0
    else:
        print("âš ï¸  GPU not available, but CPU mode is supported")
        return 1

if __name__ == "__main__":
    exit_code = check_gpu()
    sys.exit(exit_code)

